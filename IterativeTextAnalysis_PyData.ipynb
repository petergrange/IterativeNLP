{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Text Analysis with Yelp Review Data\n",
    "## By: Peter Grange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code: https://github.com/petergrange/IterativeNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** I want to understand what aspects of customersâ€™ experiences inform how they rate business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** I want to explore how topic modeling works with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**  My analysis is an unsupervised learning problem topic-modelling Yelp Review data with a goal of extracting themes that lead to high or low star ratings. I will specifically be looking at reviews of pizza places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: An Iterative Approach\n",
    "<ol>\n",
    "<li> Basic Summary of Data\n",
    "<li>Term Frequency - Inverse Document Frequency (tf-idf): create bag-of-words and weight important words\n",
    "<li>K-Means: cluster review categories at a high level, business category and restaurant type\n",
    "<li>Latent Dirichlet Allocation (LDA): models topics to confirm the effectiveness of the K-Means Clustering\n",
    "<li>Bucket by Star Rating: gain insights based off of words and word combinations that appear in different rating categories\n",
    "<li> Another tf-idf: remove category specific words\n",
    "<li> Another LDA : model topics to hone in on key ideas and key word combinations within a cluster\n",
    "<li> Recommendations to Businesses\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Cool Technical Insight:\n",
    "The key technical insight is that an iterative application of NLP techniques reveals progressively deeper themes in the textual data. The first pass of tf-idf and K-Means produces high level themes (in this case, business category and restaurant type) while the subsequent pass of tf-idf and LDA hone in on lower level themes (in this case, key ideas or business features that lead to high or low reviews).\n",
    "\n",
    "This iterative approach, while applied here to business review data, could be used with all sorts of NLP data. Any situation where honing in on different thematic strata within text data is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Basic Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports - Basic and Visualization Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import for logging\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports - scikit-learn Vector Space Modeling Packages\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports - Gensim Vector Space Modeling Packages\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "\n",
    "# For Speeding up Gensim\n",
    "import cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Business Problem\n",
    "\n",
    "There is a plethora of business questions that business owners have. The problem is how to answer those questions with the available data.\n",
    "\n",
    "There are some questions that every business has, particularly small, service-oriented businesses, like restaurants. What do my customers think about my business? My service? My quality? What do my customers care about? What gives them a positive or negative experience? What are they telling others about my business? How do I compare to my competitors? Etc.\n",
    "\n",
    "For a long time, these questions were hard to answer. You had to ask customers, create surveys, read isolated blogs, etc. But now with sites like Yelp, tons of relevant data is at business owners finger tips. Unfortunately, this data may not be organized to show what are common themes in customer reviews. The data does not initially allow you to compare your business to other similar business. In short, it takes work to turn the wealth of data into actionable information.\n",
    "\n",
    "In this project, I seek to use Natural Language Processing (NLP) techniques to hone in on relevant business categories and pertinent topics to elucidate customers thoughts on specific business categories, to show what makes customers happy or unhappy enough to write reviews and share their thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Data Set\n",
    "Yelp provides a large, clean data set with over 2.5M reviews. The data set is available here: https://www.yelp.com/dataset_challenge. This freed me up to focus right on analysis instead of having to work to compile a data set through web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 56.792s.\n"
     ]
    }
   ],
   "source": [
    "# Importing Data Set: available at https://www.yelp.com/dataset_challenge\n",
    "t0 = time()\n",
    "yrev = pd.read_csv('yelp_review.csv', sep=',')\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2685065</th>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>vwmqHxxmy9rEAwhbkLXmnQ</td>\n",
       "      <td>3</td>\n",
       "      <td>He stood in the face of a 2.5 star biz, and br...</td>\n",
       "      <td>review</td>\n",
       "      <td>nELVJlkX8T0mUAArSPSJxw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685066</th>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>2016-07-11</td>\n",
       "      <td>DDmiTM_jMhshjYkXk5Sshg</td>\n",
       "      <td>1</td>\n",
       "      <td>2 pm Monday afternoon. Out of sour cream (ridi...</td>\n",
       "      <td>review</td>\n",
       "      <td>maAimqEE4G483rtifPKlYg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id        date               review_id  stars  \\\n",
       "2685065  DH2Ujt_hwcMBIz8VvCb0Lg  2016-04-30  vwmqHxxmy9rEAwhbkLXmnQ      3   \n",
       "2685066  DH2Ujt_hwcMBIz8VvCb0Lg  2016-07-11  DDmiTM_jMhshjYkXk5Sshg      1   \n",
       "\n",
       "                                                      text    type  \\\n",
       "2685065  He stood in the face of a 2.5 star biz, and br...  review   \n",
       "2685066  2 pm Monday afternoon. Out of sour cream (ridi...  review   \n",
       "\n",
       "                        user_id  votes_cool  votes_funny  votes_useful  \n",
       "2685065  nELVJlkX8T0mUAArSPSJxw         4.0          5.0           4.0  \n",
       "2685066  maAimqEE4G483rtifPKlYg         0.0          0.0           0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining the Basic Features of the 2.6M record Data Set; I'm examining \"tail\" instead of \"head\" to confirm the number or records.\n",
    "yrev.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "Here are the features (columns) of the Yelp Review Data Set:\n",
    "\n",
    "Variable | Description | Type of Variable\n",
    "---| ---| ---\n",
    "Business_ID | An ID unique to each business | Alpha-Numeric - Continuous\n",
    "Date | Date of review | Date - Continuous \n",
    "Review_ID | A unique ID of each review, Table Primary Key | Alpha-Numeric - Continuous\n",
    "Stars | The star rating assigned by the user to the business, ranging from integers 1 through 5 | Numerical - Continuous\n",
    "Text | Free-form user inputed text reviewing the business | Textual \n",
    "User_ID | An ID unique to each user | Alpha-Numeric - Continuous\n",
    "Votes_Cool | A count-number of the \"cool\" upvotes of a particular review | Numerical - Continuous\n",
    "Votes_Funny | A count-number of the \"funny\" upvotes of a particular review | Numerical - Continuous\n",
    "Votes_Useful | A count-number of the \"useful\" upvotes of a particular review | Numerical - Continuous\n",
    "\n",
    "I will only be looking at Stars and Text columns since I want to understand what leads users to reviews businesses high or low.\n",
    "\n",
    "**Expansion:** If I were a specific business, I could hone in on Business_ID. If I wanted to understand user reviewing habits, I would look at User_ID. It would be facinating to explore if there are common elements in reviews that get upvoted as \"useful.\" The data set contains tons of material for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistic of the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are...\n",
      "\t85540 different business being reviewed\n",
      "\t2685067 total reviews (this is the number of records in the data set)\n",
      "\t686556 different users reviewing business\n",
      "\t1447187.0 total 'votes_cool' upvotes\n",
      "\t1157422.0 total 'votes_funny' upvotes\n",
      "\t2703358.0 total 'votes_useful' upvotes\n"
     ]
    }
   ],
   "source": [
    "print \"There are...\"\n",
    "print \"\\t\", yrev.business_id.nunique(), \"different business being reviewed\"\n",
    "print \"\\t\", yrev.review_id.nunique(), \"total reviews (this is the number of records in the data set)\"\n",
    "print \"\\t\", yrev.user_id.nunique(), \"different users reviewing business\"\n",
    "print \"\\t\", yrev.votes_cool.sum(), \"total 'votes_cool' upvotes\"\n",
    "print \"\\t\", yrev.votes_funny.sum(), \"total 'votes_funny' upvotes\"\n",
    "print \"\\t\", yrev.votes_useful.sum(), \"total 'votes_useful' upvotes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Star Data\n",
    "\n",
    "The simple bar chart shows that there are more higher reviews than lower reviews. There are actually more 5 star reviews than 1, 2, and 3 star reviews put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average star rating across all reviews is 3.76\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAERCAYAAABCcWF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNJKkov4/xpMe4i0doLcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b4034ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='stars', data = yrev) # ADD FEQUENCY PRESENTAGES\n",
    "print \"The average star rating across all reviews is\", round(yrev.stars.mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias in the data!?!?!\n",
    "There are two main ways that the data is biased, or not fully representative of the population.\n",
    "\n",
    "1. This is only data of people who use yelp and who review on yelp. With the exception of serial reviewers, reviews often come from very happy or more often very unhappy customers, which naturally skews the data. That said, it does show what people care enough about to bother reviewing for. So it tends to show the issues that customers get motivated over.\n",
    "2. Yelp describes the data set as \"includes information about local businesses in 10 cities across 4 countries.\" So while this is a good representation and enough to train a model off of, it is not a complete representation. Also, if we want insights, say, into the market in the USA or in rural areas, there will be skew based off of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am cleaning up the data set by dropping any rows that have missing values (there was only one or two) and by limiting the data to columns that are pertinent to my analysis, which are the stars and text columns. I am creating an abridged data frame mostly to speed up performance by avoiding unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      4  Mr Hoagie is an institution. Walking in, it do...\n",
       "1      5  Excellent food. Superb customer service. I mis..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning up data by dropping missing values and limiting columns only to the relavent ones\n",
    "\n",
    "data = yrev[['stars', 'text']].dropna() #dropping missing values and renaming cleaned dataset\n",
    "data.head(2) # Examining the top two lines of quaried data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Clustering: Business Type & Restaurant Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three problems. \n",
    "1. There is too much data. My computer cannot handle 2.5M records, even with only 2 columns.\n",
    "2. The main column ('text') has no structured category markers. It is not organized by business type (Restaurants, Car Shops, Hair Salons, etc.)\n",
    "3. The main column ('text') is not structured by type of restaurants (pizza places, sandwich shops, asain, italian, etc.) \n",
    "\n",
    "So I need to limit the size of the data being explored and then explore the data using NLP models to hone in on the specific category I am interested in, which in this case is pizza places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 10000 #number of samples\n",
    "n_features = 2000 #number of features\n",
    "n_topics = 10 #number of topics\n",
    "n_top_words = 20 #number of top words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Vectorization and Weighting-Transformation (term frequency - inverse document frequency)\n",
    "Before I do any analysis, I need to convert the review data, which is stuctured as English sentances into a number vector that can be analyized by the computer. I will be doing a two step process in one step. \n",
    "1. The first step is to create a count vector, also called 'bag-of-words'. This count vector is simply a count of how many times a word from our dictionary (feature) shows up in particular sentance (row or sample). We could stop here with a count vector. This is enough to run a model on. But the issue with the count vector is that it will prioritize common words which may hinder our ability to generalize from the data.\n",
    "\n",
    "2. So the second step, to avoid this issue, is to weight the the term frequency, represented in the count vector, by the inverse of the document frequency. Essentially, while term frequency assumes that more frequent terms are generally more telling for what a review is about, document frequency adds that if a term is in more documents, then it is probably less important for telling key information than a word that is in less documents.\n",
    "\n",
    "This two step vectorization and transformation is called term frequency - inverse document frequency transformation or tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for Category Clustering...\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for Category Clustering for Business Type.\n",
    "print(\"Extracting tf-idf features for Category Clustering...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=5,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english',\n",
    "                                   ngram_range=(1,2))\n",
    "tfidf = tfidf_vectorizer.fit_transform(data[:n_samples]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on the tf-idf transformation. \n",
    "1. I excluded common \"stop words,\" which are common parts of speech that do not tell much about what is really being talked about (these are things like articles (a, an, the), prepositions (of, for, by, etc.), conjunctions (and, but, which, etc.), pronouns (I, you, we, them, etc.), etc.)\n",
    "2. I am examining 10000 samples. This will function as a training set (one used to set up a model), as well as ensuring that I do not crash my computer with all 2.6M samples.\n",
    "3. I exclude words that are in 95% of the documents. The assumption is that if a word shows up in more than 95% of the documents it does not give us much insight about the documents is about. Essentially, words that show up in most document are probably filler words, the ones necessary to move from key idea to key idea, while words that show up in less documents are probably the key ideas that actually show what the document is about.\n",
    "3. I excluded words whose count frequency was less than 5. If a word does not show up 5 times in 10000 reviews, than I am concluding that it is not very telling for my analysis. Plus at this point, I want to hone in on over arching terms to form a good cluster around categories.\n",
    "4. I am examining 2000 features, that is my dictionary will only include the 2000 most common feature (single word or 2-gram; see next list item).\n",
    "5. I am looking at both single words and two word combination (a 2-gram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have created a weighted number vector, I want to see how these number vectors cluster around each other, with the assumption being that if they cluster in vector space; they should cluster in topical, semantical, or categorical as well. To do this, I will use the K-Means clustering algorithm. K-Means starts with random cluster centers and then assigns all of the samples to the cluster they are closest to. Then it re-adjusts the cluster center based off of the samples now assigned to the cluster. Then it re-assigns the samples to the new cluster center that it is now closest to. It continues to do this until there is no change between iterations in which samples are assigned to which cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating Category Clusters on the tf-idf vectors with K-Means\n",
    "kmeansF = KMeans(n_clusters=n_topics, random_state=0, n_jobs=2).fit(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the K-Means cluster number back to the data set\n",
    "\n",
    "I am adding the K-Means cluster number back to the corresponding row (sample) so that I can analysis the data grouped by cluster. I will need to check over the clusters to make sure that K-Means actually worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cluster ID\n",
       "0      4  Mr Hoagie is an institution. Walking in, it do...           4\n",
       "1      5  Excellent food. Superb customer service. I mis...           4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new data frame with only the first 10K rows and adding in the cluster IDs\n",
    "labeled = data[:kmeansF.labels_.size]\n",
    "labeled['cluster ID'] = kmeansF.labels_\n",
    "labeled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of the star rating, shows that this sample of the data is close but not perfectly reprsentative of the data. In the full data set, there are more 1 star reviews than 3 star reviews. Also, the mean star rating in the original is 3.76, while it is 3.61 in this new set. Even still, the distribution looks close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean star rating for this subset of data is 3.61\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFRkSkqQiQ0KSVGRISJKK/j/QR0lSLuYTjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b406bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='stars', data = labeled)\n",
    "print \"Mean star rating for this subset of data is\", round(labeled.stars.mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing Reviews by Cluster ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my goal is to a hone in on a specific business category, in this case I have chosen pizza places, I need to bracket the reviews by cluster ID and examine each cluster to see what it appears to be clustering on. I can visually examine a sample of each cluster...time consuming and risks being skewed by an inaccurate sample representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grouping data by cluster ID column...ending with 10 groups\n",
    "clusters = labeled.groupby(['cluster ID'])\n",
    "\n",
    "# Creating seperate data frames for each cluster group\n",
    "clust0 = clusters.get_group(0)['text']\n",
    "clust1 = clusters.get_group(1)['text']\n",
    "clust2 = clusters.get_group(2)['text']\n",
    "clust3 = clusters.get_group(3)['text']\n",
    "clust4 = clusters.get_group(4)['text']\n",
    "clust5 = clusters.get_group(5)['text']\n",
    "clust6 = clusters.get_group(6)['text']\n",
    "clust7 = clusters.get_group(7)['text']\n",
    "clust8 = clusters.get_group(8)['text']\n",
    "clust9 = clusters.get_group(9)['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Identification: Visually\n",
    "I will identify each cluster by visually inspecting the first 50 rows. And then label them based on what I appears to be the central theme.\n",
    "\n",
    "This next cell prints the top 50 reviews of each cluster (This number can be set by setting the 'num' variable in the prt function. Each needs to be visually examined to identify the theme of the cluster. The clusters can then be labelled and the pertinent cluster(s) selected. In this case, the pizza related themes clustered nicely in cluster #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment out the code below if you have any interest in examine each category.\n",
    "Code for category #0 and #1 is in the cells below.\n",
    "I have summarized the 10 categories below as well.\n",
    "The fuction directly below, prints out the text review (limited to the first 200 characters, delete the [:200] to print them in their entirety) for the first 50 reviews (you can pick less by setting num = to whatever number you'd like).\n",
    "\"\"\"\n",
    "def prt(x, num = 50):\n",
    "    for i in x[:num]:\n",
    "        print \"\\n\", i[:200],\n",
    "\n",
    "#for X in xrange(0, 10):\n",
    "#    y = 'print clust%d.head(50)' %(X)\n",
    "#    z =  'print prt(clust%d, num = 50)' %(X)\n",
    "#    print \"Printing Cluster #%d\" %(X)\n",
    "#    exec(y)\n",
    "#    exec(z)\n",
    "#    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Business Category Cluster Summary:\n",
    "My goal is to hone in only on Topic Clusters that focusing on pizza oriented business's within the Food industry.\n",
    "\n",
    "Here is a summary of what each topic seemed to be focusing on.\n",
    "\n",
    "6. Category #0: Hair Salons\n",
    "3. ***Category #1: Restaurants / Pizza / Italian***\n",
    "5. Category #2: Misc \n",
    "7. Category #3: Restaurants / Bar / Beer / Positive\n",
    "2. Category #4: Restaurants / Positive / Bar / Breakfast \"Kings Family Restuarant\"\n",
    "4. Category #5: Ice Cream\n",
    "10. Category #6: Grocery / Convenience / Craft Stores / Starbucks (?)\n",
    "8. Category #7: Restaurants / Sushi\n",
    "9. Category #8: Restaurants / Sandwich Shop / Fish / Mixed Reviews\n",
    "1. Category #9: Auto Mechanics / Auto Parts / Vets / Contractors / Driving Range\n",
    "\n",
    "***So I will only be examining topic #1***\n",
    "\n",
    "***Important Note*** If someone runs the above techniques, but changes some of the parameters, the cluster categories may change order. Although the breakdown of topics within the categories would likely stay very close, the order of the categories would likely change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Cluster #0 and #1\n",
    "\n",
    "Below I demonstate what the visual inspection process is like. It can be tedious, but often a them jumps out at you. I cluster #0 words like hair, cut, salon, updo, etc. are almost always in the first line of the review. For cluster #1 words like pizza, cheese, chrust, etc. are in the first usually in the lines if the review. I will limit the number printed to save space, but I would examine about 50 reviews, if I were going to try to identify the clusters visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is Cluster #0, which I've identified as 'Hair Salons'\n",
      "1735    Now I'm picky about my hair, but Mane Attracti...\n",
      "1736    I have been getting my hair cut and hi-lighted...\n",
      "1737    Let me just tell you, I have really, really di...\n",
      "1892    My Kingston cooper is a havanese and is a goof...\n",
      "1959    Can't recommend this barber highly enough.  I ...\n",
      "2009    Nothing spectacular, but I go there regularly,...\n",
      "2010    i'm not sure why this place has bad reviews. i...\n",
      "2012    Went here with a friend for his haircut. It's ...\n",
      "2013    I went there today! The cut was terrible! I ha...\n",
      "2014    I used to cut my own hair, haphazardly, with a...\n",
      "Name: text, dtype: object\n",
      "\n",
      "\n",
      "Now I'm picky about my hair, but Mane Attractions was so bad that I walked out after about 15 minutes of watching the stylists work on other clients.\n",
      "\n",
      "I had desperately needed a haircut and walked in  \n",
      "I have been getting my hair cut and hi-lighted at Mane Attractions for over 5 years, by Sue, the owner. I am always extremely happy with the way my hair looks.   My hair is very fine and I don't have  \n",
      "Let me just tell you, I have really, really difficult hair.  type 3b Naturally curly, 100% grey, I dye it dark and mess with the color myself. ( never good)  If you want to know where to get a good ha \n",
      "My Kingston cooper is a havanese and is a goofy handful and they handled him well. I loved his hair cut. I changed from a different groomer to here. He's only been here once about a month ago but I lo \n",
      "Can't recommend this barber highly enough.  I was in town, and walked over here.  I realized that they only take cash, but Paul Pirollo just says 'don't worry about it, bring it later'.  There were tw \n",
      "Nothing spectacular, but I go there regularly, and generally get a cut that works fine for at least a couple of months.  They did a good job after I had a botched cut overseas (hairdressers in Japan a \n",
      "i'm not sure why this place has bad reviews. its par for thecourse for supercuts. standard cut 16.95 is a bit pricy but they always do exactly what I say. i've simple hair so it works well for me. emp \n",
      "Went here with a friend for his haircut. It's been a long time since I've been to a barber shop or haircut salon/store, but from what I remember this place seems completely average. The hair stylists  \n",
      "I went there today! The cut was terrible! I have an awful experience. They lady that cut my hair was nice but she wanted to leave early so she made a disaster in my head! \n",
      "I used to cut my own hair, haphazardly, with a pair of Andis clippers.  Once, due to a series of unfortunate events, I ended up needing a new passport photo the day I cut my hair.  I hadn't realized q None\n"
     ]
    }
   ],
   "source": [
    "print \"Here is Cluster #0, which I've identified as 'Hair Salons'\"\n",
    "print clust0.head(10)\n",
    "print \"\\n\", prt(clust0, num = 10),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is Cluster #1, which I've identified as 'Restaurants / Pizza / Italian'\n",
      "3      PROS: Italian hoagie was delicious.  Friendly ...\n",
      "45     This would be my local haunt, if I were ever t...\n",
      "212    Recommended. 16 inch pizza on special was chea...\n",
      "213    Some of the worst pizza I've ever had.  We use...\n",
      "265    Papa J's is by far my favorite restaurant in P...\n",
      "271    I went there for dinner last night with a clie...\n",
      "272    What a wonderful surprise found in Carnegie PA...\n",
      "273    Yay, I'm a fan but sometimes service is a litt...\n",
      "275    Yay, I'm a fan of the white pizza.  Had take o...\n",
      "276    We met our good friends from Morgantown here f...\n",
      "Name: text, dtype: object\n",
      "\n",
      "PROS: Italian hoagie was delicious.  Friendly counter employee. The restaurant was clean and neat. \n",
      "\n",
      "CONS: The pizza was not good.  Pre-formed crust, NOT fresh dough.  The price of the failure of a pi \n",
      "This would be my local haunt, if I were ever to relocate to the Pittsburgh area. What a great little place! Such friendly staff, and some damn good eats!\n",
      " \n",
      "It was so great, that we actually went there \n",
      "Recommended. 16 inch pizza on special was cheap. Fast service. Not the best pizza but above average. \n",
      "Some of the worst pizza I've ever had.  We used a coupon from the paper for a 2 topping 8 cut Sicilian. First of all the pizza wasn't even cut through, and the sad attempt at cutting was so uneven tha \n",
      "Papa J's is by far my favorite restaurant in Pittsburgh, my hometown.  I eat there almost every time I visit, and everything I've ever ordered has been fantastic.  Fresh ingredients, simple preparatio \n",
      "I went there for dinner last night with a client.  This is second time I visited.  I had a scotch and he had a Guiness.  The (-1) is for drink selection. Just stock some better beers and higher end sc \n",
      "What a wonderful surprise found in Carnegie PA, just south of Pittsburgh.  I was in town on business with a couple co-workers and after having a not so great meal the night before, we asked one of the \n",
      "Yay, I'm a fan but sometimes service is a little slow, it was very good for us this visit.  Go to Papa j's every once in a while but mostly for the White Pizza.  It is the best white pizza I have ever \n",
      "Yay, I'm a fan of the white pizza.  Had take out.  \n",
      "\n",
      "The bar was jumping when I picked up our order.\n",
      "\n",
      "The white pizza is so delicious...with garlic, spinach, feta, and added some veggies.  Tried the R \n",
      "We met our good friends from Morgantown here for lunch today and were really impressed with the place itself and the menu. \n",
      "\n",
      "I had read a few of the reviews ahead of time and the pizza was mentioned m None\n"
     ]
    }
   ],
   "source": [
    "print \"\\nHere is Cluster #1, which I've identified as 'Restaurants / Pizza / Italian'\"\n",
    "print clust1.head(10) # this is the pizza cluster\n",
    "print prt(clust1, num = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem with Visually Identifying Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primary problem with identifying the clusters visually is the tedious nature of the work, and the limitation of only really being able to focus on the 25 to 50 rows, even that number can be pretty time consuming and any less is not a sufficent representation. I can also use LDA to either confirm cluster identity or to actually identify the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Identification: LDA\n",
    "\n",
    "A clear advantage of using LDA to identify the clusters is that it will take into account all pertinent samples instead of just 25 to 50. It also is much quicker when trying to identify many clusters.\n",
    "\n",
    "Below I will demonstrate this on Cluster #1 since I am honing in an pizza places.\n",
    "\n",
    "I am creating a Count Vector without inverse weighting for terms in most document (I'm not using the \"idf\" weighting), since I want to see the terms that permeate the documents to confirm that the clustering worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only consider at max 1000 features (words in our vocab)\n",
    "vectorizer = CountVectorizer(max_features = n_features, \n",
    "                             stop_words='english',\n",
    "                             min_df=3,\n",
    "                             ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fit and Transform in 1 step\n",
    "### `fit` learns the vocabulary of the reviews\n",
    "### Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "C1_matrix = vectorizer.fit_transform(clust1)\n",
    "\n",
    "# Creating a dictionary of word IDs to words  which is an input in the LDA model\n",
    "id2word = dict(enumerate(vectorizer.get_feature_names()))\n",
    "\n",
    "# Converting the word-matrix into gensim's format corpus\n",
    "corpusC1 = Sparse2Corpus(C1_matrix, documents_columns = False)\n",
    "\n",
    "# Fitting an Latent Dirichlet Allocation model with Cluster 2 and all Star Levels\n",
    "lda_model = LdaModel(corpus=corpusC1, id2word=id2word, num_topics=n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 (8, u'0.056*pizza + 0.025*good + 0.017*place + 0.010*crust + 0.010*cheese + 0.008*ordered + 0.007*sauce + 0.007*just + 0.006*great')\n",
      "Topic: 1 (6, u'0.058*pizza + 0.027*good + 0.011*cheese + 0.009*crust + 0.009*place + 0.009*really + 0.008*like + 0.007*just + 0.007*time')\n",
      "Topic: 2 (9, u'0.071*pizza + 0.014*place + 0.011*cheese + 0.010*good + 0.010*just + 0.009*time + 0.009*sauce + 0.008*ve + 0.007*ordered')\n",
      "Topic: 3 (2, u'0.044*pizza + 0.014*good + 0.012*cheese + 0.012*crust + 0.011*just + 0.009*place + 0.009*sauce + 0.008*like + 0.007*don')\n",
      "Topic: 4 (4, u'0.026*pizza + 0.016*place + 0.016*cheese + 0.010*good + 0.009*great + 0.009*crust + 0.007*time + 0.006*just + 0.005*night')\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5\n",
    "n_words_per_topic = 9\n",
    "for ti, topic in enumerate(lda_model.show_topics(num_topics = num_topics, num_words= n_words_per_topic)):\n",
    "    print(\"Topic: %d\" % (ti)), (topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Insights:\n",
    "<ul>\n",
    "<li>There is definitely a very nice cluster around words that reference pizza places. So the K-Means cluster worked at honing in on this restaurant category. \n",
    "<li>But the topics only really give word groups that we would assume seeing in a topic cluster within the pizza category.\n",
    "<li> It is progress, but the results are cluttered by cluster specific common words, like pizza, cheese, etc. \n",
    "</ul>\n",
    "\n",
    "So we should run another tf-idf and group by star levels before running this LDA model to hone in on specify customer preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing Reviews Cluster by Star Rating and Examining Major Review Topic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my goal is to understand what business features and aspects of the customer experience, motivate customers to reviews businesses high or low, I will need to group this cluster by different star levels and then extract key topics for each star level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping the clustered data for cluster 1 by stars column...ending with 5 groups for each cluster\n",
    "C1 = clusters.get_group(1)\n",
    "C1stars = C1.groupby(['stars'])\n",
    "\n",
    "# Creating seperate data frames for each cluster and star combination\n",
    "C1_S1 = C1stars.get_group(1)['text']\n",
    "C1_S2 = C1stars.get_group(2)['text']\n",
    "C1_S3 = C1stars.get_group(3)['text']\n",
    "C1_S4 = C1stars.get_group(4)['text']\n",
    "C1_S5 = C1stars.get_group(5)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213     Some of the worst pizza I've ever had.  We use...\n",
       "329     Worst service of all time. 2 hours for a pizza...\n",
       "671     If you want terrible pizza go here. Save money...\n",
       "672     Ordered a hot sausage Parmesan hoagie ,fried z...\n",
       "1058    Awful everything. From the bad service, to the...\n",
       "1080    How does this place still exist of every place...\n",
       "1083    Possibly the worst overpriced pizza there is. ...\n",
       "1599    This was a Good place to get pizza.  As far as...\n",
       "2062    Bleh. I've tried a lot of pizza places and thi...\n",
       "2064    Horrible Food don't waste your money\\n\\nThis i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of what the new data frames / series look like\n",
    "C1_S1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploying Topic Extraction for each star level with another tf-idf\n",
    "\n",
    "Since my goal now is to move beyond category level words and features, to topic words and features and sentiment words and features, I will want a weighted number vector instead of a simple count vector. So I will be using tf-idf again, this time on top of the data grouped by K-Means cluster, grouped by star level. I will be looking at 1, 3, and 5 star reviews, since we want to understand what makes customer really happy (star 5) and really unhappy (star 1) about the business with star 3 for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Extraction from 1 Star Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using LDA to extract key (high-probablility) words and word combinations from 1 star reviews from Cluster #1 (pizza cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for Topic Clustering for 1 Star Reviews in Cluster 1, fitting LDA model, printing topics...\n",
      "\n",
      " Topic: 0 (7, u'0.023*place + 0.021*came + 0.019*greasy + 0.019*ordered + 0.018*mushrooms + 0.017*food + 0.016*like + 0.015*cooked + 0.014*frozen + 0.012*service + 0.012*mistake + 0.012*fries + 0.012*extremely + 0.012*menu + 0.012*parma + 0.012*pizza parma + 0.012*flavor + 0.012*frozen pizza + 0.012*box + 0.011*didn')\n",
      "\n",
      " Topic: 1 (9, u'0.017*quality + 0.017*cheese + 0.015*away + 0.015*cold cheese + 0.015*place + 0.015*hot + 0.014*want + 0.014*50 + 0.014*cold + 0.014*terrible + 0.013*decent + 0.013*pizzas + 0.013*ordered + 0.013*today + 0.013*hour + 0.012*food + 0.012*great + 0.012*called + 0.011*time + 0.011*got')\n",
      "\n",
      " Topic: 2 (6, u'0.024*pretty + 0.020*40 + 0.017*went + 0.015*new + 0.015*ordered + 0.015*took + 0.014*medium + 0.014*fries + 0.013*wait + 0.013*going + 0.013*hour + 0.012*used + 0.012*told + 0.011*lot + 0.011*saw + 0.011*tastes + 0.011*pizza places + 0.011*ve + 0.011*years + 0.011*places')\n",
      "\n",
      " Topic: 3 (3, u'0.025*okay + 0.020*like + 0.020*just + 0.018*dough + 0.015*tasted + 0.014*good + 0.014*awful + 0.014*quality + 0.013*oven + 0.013*greasy + 0.012*night + 0.012*plus + 0.012*eating + 0.011*cheese + 0.010*place + 0.010*food + 0.010*time + 0.010*bad + 0.010*eaten + 0.010*tastes')\n",
      "\n",
      " Topic: 4 (5, u'0.021*money + 0.020*bad + 0.016*awful + 0.016*salad + 0.015*cooked + 0.014*toppings + 0.014*service + 0.012*mushrooms + 0.012*cheese + 0.012*terrible + 0.012*waste + 0.011*place + 0.011*quality + 0.011*came + 0.011*expect + 0.011*don + 0.011*waste money + 0.010*half + 0.010*eat + 0.010*try')\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for Topic clustering.\n",
    "print(\"Extracting tf-idf features for Topic Clustering for 1 Star Reviews in Cluster 1, fitting LDA model, printing topics...\")\n",
    "tfidf_vectorizer2 = TfidfVectorizer(max_df=0.97, min_df=3,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english',\n",
    "                                   ngram_range=(1,3))\n",
    "C1_S1_tfidf = tfidf_vectorizer2.fit_transform(C1_S1)\n",
    "\n",
    "# Creating a dictionary of word IDs to words  which is an input in the LDA model\n",
    "id2word2 = dict(enumerate(tfidf_vectorizer2.get_feature_names()))\n",
    "\n",
    "# Converting the word-matrix into gensim's format corpus\n",
    "corpusC1_S1 = Sparse2Corpus(C1_S1_tfidf, documents_columns = False)\n",
    "\n",
    "# Fitting an Latent Dirichlet Allocation model with Cluster 2, Star 1 Data\n",
    "lda_model_C1_S1 = LdaModel(corpus=corpusC1_S1, id2word=id2word2, num_topics=n_topics)\n",
    "\n",
    "n_words_per_topic = 20\n",
    "for ti, topic in enumerate(lda_model_C1_S1.show_topics(num_topics = num_topics, num_words= n_words_per_topic)):\n",
    "    print(\"\\n Topic: %d\" % (ti)), (topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from Word Combinations\n",
    "Here I am pulling out common 2-grams and 3-grams (2 and 3 word combinations). This often start to give more insight into what is being expressed. Limiting the high frequency words a bit (those occuring in 97% of the sample), helps to eliminate category words, like pizza (by itself), and hone in on more meaningful combinations, like cold pizza, waste money, prices high, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices high\n",
      "looked like\n",
      "waste money\n",
      "best pizza\n",
      "pizza better\n",
      "pizza ve\n",
      "pizza wasn\n",
      "terrible pizza\n",
      "good pizza\n",
      "called pizza\n",
      "cold cheese\n",
      "frozen pizza\n",
      "tasted like\n",
      "know good\n",
      "know good pizza\n",
      "pizza parma\n",
      "pizza pizza\n",
      "pizza places\n",
      "pizza crust\n",
      "cheese pizza\n",
      "worst pizza\n",
      "cheese toppings\n"
     ]
    }
   ],
   "source": [
    "# Printing all frequent 2-grams and 3-grams\n",
    "C1_S2_vocab = tfidf_vectorizer2.vocabulary_\n",
    "\n",
    "for key, value in C1_S2_vocab.iteritems() :\n",
    "    if \" \" in key:\n",
    "        print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from 1 Star Reviews\n",
    "\n",
    "Issues: \n",
    "- Tempeture: Cold pizza get a number of mentions in the LDA topics\n",
    "- Timeliness: \"waited,\" \"minutes,\" \"hours\"\n",
    "- Value: terms like \"waste money,\" \"high prices,\" \"overpriced\"\n",
    "\n",
    "As a business owner, how do you ensure that pizzas are consumed hot, because cold pizza is a major, but controllable, issue that leads to people having a negative experience and marking poorly rating pizza businesses. Also, how do you ensure that you are giving people a good value in terms of price to quality. From this LDA, cold pizza and poor value arise as key reasons people rate pizza businesses poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Extraction from  3 Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for Topic Clustering for 3 Star Reviews in Cluster 1, fitting LDA model, printing topics...\n",
      "\n",
      " Topic: 0 (7, u'0.011*weird + 0.008*crust + 0.008*best + 0.008*best pizza + 0.008*kind + 0.008*just + 0.008*minutes + 0.007*cold + 0.007*large + 0.007*cheese + 0.007*quality + 0.007*average + 0.007*guy + 0.007*hot + 0.007*try + 0.007*dough + 0.007*eat + 0.007*place + 0.007*new + 0.007*ordered')\n",
      "\n",
      " Topic: 1 (4, u'0.012*deliver + 0.011*flavor + 0.010*good sauce + 0.010*sauce + 0.010*sure + 0.009*fries + 0.009*ok + 0.009*order + 0.009*special + 0.008*got + 0.008*enjoy + 0.008*come + 0.008*pizza good + 0.008*decent + 0.007*eating + 0.007*melted + 0.007*options + 0.007*getting pizza + 0.007*arrived + 0.006*standard')\n",
      "\n",
      " Topic: 2 (3, u'0.010*crust + 0.009*great + 0.009*salad + 0.008*slices + 0.008*great pizza + 0.007*local + 0.007*villa reale + 0.007*villa + 0.007*reale + 0.007*delicious + 0.007*lettuce + 0.007*pizza pretty + 0.007*pepperoni + 0.007*lunch + 0.007*stuff + 0.007*pizza ok + 0.007*cheese + 0.007*said + 0.006*mushrooms + 0.006*pretty good')\n",
      "\n",
      " Topic: 3 (6, u'0.010*cheese + 0.009*salad + 0.008*water + 0.008*really + 0.008*place + 0.007*slice + 0.007*villa + 0.007*area + 0.007*great + 0.007*little + 0.006*shrimp + 0.006*bit + 0.006*easily + 0.006*time + 0.006*reale + 0.006*villa reale + 0.006*cut + 0.006*crispy + 0.006*waitress + 0.006*ll')\n",
      "\n",
      " Topic: 4 (2, u'0.016*slow + 0.011*home + 0.011*service + 0.010*average + 0.009*fine + 0.008*sauce + 0.008*time + 0.007*order + 0.007*places + 0.007*crust + 0.007*uncooked + 0.007*style pizza + 0.006*great + 0.006*canned + 0.006*style + 0.006*guess + 0.006*pizza parma + 0.006*parma + 0.006*giving + 0.006*tomatoes')\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for Topic clustering.\n",
    "print(\"Extracting tf-idf features for Topic Clustering for 3 Star Reviews in Cluster 1, fitting LDA model, printing topics...\")\n",
    "\n",
    "C1_S3_tfidf = tfidf_vectorizer2.fit_transform(C1_S3)\n",
    "\n",
    "# Creating a dictionary of word IDs to words  which is an input in the LDA model\n",
    "id2word2 = dict(enumerate(tfidf_vectorizer2.get_feature_names()))\n",
    "\n",
    "# Converting the word-matrix into gensim's format corpus\n",
    "corpusC1_S3 = Sparse2Corpus(C1_S3_tfidf, documents_columns = False)\n",
    "\n",
    "# Fitting an Latent Dirichlet Allocation model with Cluster 2, Star 1 Data\n",
    "lda_model_C1_S3 = LdaModel(corpus=corpusC1_S3, id2word=id2word2, num_topics=n_topics)\n",
    "\n",
    "for ti, topic in enumerate(lda_model_C1_S3.show_topics(num_topics = num_topics, num_words= n_words_per_topic)):\n",
    "    print(\"\\n Topic: %d\" % (ti)), (topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza came\n",
      "really good\n",
      "good pizza\n",
      "pizza joint\n",
      "weeks ago\n",
      "just ok\n",
      "like pizza\n",
      "pizza salad\n",
      "pretty good\n",
      "crust sauce\n"
     ]
    }
   ],
   "source": [
    "# Printing all frequent 2-grams and 3-grams\n",
    "C1_S3_vocab = tfidf_vectorizer2.vocabulary_\n",
    "numprints = 0\n",
    "for key, value in C1_S3_vocab.iteritems():\n",
    "        if \" \" in key:\n",
    "            numprints += 1\n",
    "            if numprints >=11: # I am limiting the number of n-grams printed to 10 for space\n",
    "                break\n",
    "            else:\n",
    "                print key   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Insights from 3 Star Reviews\n",
    "This is exactly what we would expect. Nothing too bad or too good mentioned. 2-grams like \"decent pizza,\" \"just okay,\" and \"pretty good\" showing up. This LDA doesn't produce anything particularly informative. Three stars reviews tend to come from customers that had a rather un-noteworthy experience. Also, 2 and 3 star reviews are the least likely reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Extraction from 5 Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for Topic Clustering for 5 Star Reviews in Cluster 1, fitting LDA model, printing topics...\n",
      "\n",
      " Topic: 0 (5, u'0.013*cheese + 0.012*great + 0.012*hot + 0.011*best + 0.011*cut + 0.011*service + 0.010*order + 0.010*fresh + 0.010*just + 0.010*food + 0.010*good + 0.010*ve + 0.009*cold + 0.009*place + 0.009*time + 0.008*beto + 0.008*great pizza + 0.008*hoagie + 0.008*grew + 0.008*like')\n",
      "\n",
      " Topic: 1 (8, u'0.023*cheese + 0.016*best pizza + 0.015*best + 0.014*delicious + 0.014*sauce + 0.014*love + 0.013*good + 0.013*great + 0.012*place + 0.011*like + 0.011*favorite + 0.011*pittsburgh + 0.009*favorite pizza + 0.009*toppings + 0.009*pizza pittsburgh + 0.009*beto + 0.008*best pizza pittsburgh + 0.008*great pizza + 0.008*crust + 0.008*extra')\n",
      "\n",
      " Topic: 2 (0, u'0.018*ve + 0.012*great pizza + 0.012*white + 0.011*hoagies + 0.011*great + 0.010*stop + 0.010*good + 0.010*perfect + 0.010*white pizza + 0.010*disappointed + 0.009*place + 0.009*little + 0.009*crust + 0.009*going + 0.009*life + 0.009*wonderful + 0.008*service + 0.008*salads + 0.008*slices + 0.008*big')\n",
      "\n",
      " Topic: 3 (1, u'0.016*best + 0.014*ve + 0.013*place + 0.011*cheese + 0.010*good + 0.010*awesome + 0.010*pizza best + 0.009*years + 0.009*great + 0.009*toppings + 0.009*campiti + 0.009*eating + 0.009*try + 0.008*just + 0.008*fresh + 0.008*best pizza + 0.008*don + 0.008*pittsburgh + 0.008*love + 0.007*right')\n",
      "\n",
      " Topic: 4 (2, u'0.015*good + 0.014*pittsburgh + 0.013*sauce + 0.013*great + 0.012*place + 0.011*cold toppings + 0.011*like + 0.011*went + 0.011*awesome + 0.011*like pizza + 0.010*good pizza + 0.010*best + 0.010*toppings + 0.010*worth + 0.009*trip + 0.009*taste + 0.009*selection + 0.009*best pizza + 0.009*best pizza pittsburgh + 0.009*hands')\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for Topic clustering.\n",
    "print(\"Extracting tf-idf features for Topic Clustering for 5 Star Reviews in Cluster 1, fitting LDA model, printing topics...\")\n",
    "tfidf_vectorizer3 = TfidfVectorizer(max_df=0.90, min_df=5,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english',\n",
    "                                   ngram_range=(1,3))\n",
    "\n",
    "C1_S5_tfidf = tfidf_vectorizer3.fit_transform(C1_S5)\n",
    "\n",
    "# Creating a dictionary of word IDs to words  which is an input in the LDA model\n",
    "id2word2 = dict(enumerate(tfidf_vectorizer3.get_feature_names()))\n",
    "\n",
    "# Converting the word-matrix into gensim's format corpus\n",
    "corpusC1_S5 = Sparse2Corpus(C1_S5_tfidf, documents_columns = False)\n",
    "\n",
    "# Fitting an Latent Dirichlet Allocation model with Cluster 2, Star 1 Data\n",
    "lda_model_C1_S5 = LdaModel(corpus=corpusC1_S5, id2word=id2word2, num_topics=n_topics)\n",
    "\n",
    "for ti, topic in enumerate(lda_model_C1_S5.show_topics(num_topics = num_topics, num_words= n_words_per_topic)):\n",
    "    print(\"\\n Topic: %d\" % (ti)), (topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza pittsburgh\n",
      "good pizza\n",
      "deep dish\n",
      "love place\n",
      "pizza dough\n",
      "crust sauce\n",
      "extra cheese\n",
      "like pizza\n",
      "pizza joint\n",
      "pizza place\n"
     ]
    }
   ],
   "source": [
    "# Printing all frequent 2-grams and 3-grams\n",
    "C1_S5_vocab = tfidf_vectorizer3.vocabulary_\n",
    "\n",
    "numprints = 0\n",
    "for key, value in C1_S5_vocab.iteritems():\n",
    "    if \" \" in key:\n",
    "        numprints += 1\n",
    "        if numprints >=11: # I am limiting the number of n-grams printed to 10 for space\n",
    "            break\n",
    "        else:\n",
    "            print key     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights from 5 Star Reviews\n",
    "\n",
    "The 5 Star reviews require a bit more work to get helpful insight; I had to adjust the vectorizer parameters to get rid of all the extra gush words: best, great, etc. Customers tend to gush in the 5 star reviews, rather than critically analysis in a positive direction. The reviews mention words like \"recommend,\" they point out a few positive features like \"fresh ingredients,\" and they talk about specific features  or offerings like \"white pizza\" or talk about what \"style of pizza\" the business offers. While textual analysis offers less insights in this case, it does confirm that when you make people happy they will gush in glowing terms about your business and give you free advertising!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Business Conclusions and Recommendations\n",
    "\n",
    "For pizza businesses, the biggest issue seems to be temperature: cold pizza and cold cheese! So anyone who runs a pizza business should put effort into ensuring that pizzas are always given to the customer piping hot.\n",
    "\n",
    "Owners should audit their operations to assess the current standard \n",
    "- Are pizza's being made hot?\n",
    "- Are they being kept warm after being made?\n",
    "- Are they leaving the store hot?\n",
    "- Are they being kept warm during delivery?\n",
    "- How long is the average delivery time?\n",
    "- How much do pizzas cool during that time? etc. \n",
    "and they should seek to address any of the areas where they fall short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "A main purpose of this analysis was to demonstrate a natural language processing approach that iteratively applies various machine learning techniques to hone in on specific categories and then specific topics within textual data.\n",
    "\n",
    "While this example, may not resonate with many business, the approach taken here has a wealth of applications, helping businesses gain valuable insights from textual data, such as using tfidf and LDA to examine successful text advertisements to understand what are the common topics or themes from successful ads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Next Steps / Further Applications\n",
    "\n",
    "1. Explore more advanced Machine Learning techniques\n",
    "1. Create a category prediction engine based off analysis\n",
    "1. Create a star prediction engine based off analysis\n",
    "1. Turn analysis into a product\n",
    "1. Analysis votes_useful\n",
    "1. Specific Word Frequency\n",
    "1. Length of Review to Star\n",
    "1. Pull data from yelp API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code: https://github.com/petergrange/IterativeNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option: Category Prediction Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, ..., 9, 9, 9], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing Kmeans Predict Feature\n",
    "testpredict = tfidf_vectorizer.fit_transform(data[10000:20000]['text'])\n",
    "testpredict\n",
    "\n",
    "#Predict Feature Works...This could be turned into a feature of the project if time permits\n",
    "kmeansF.predict(testpredict)\n",
    "\n",
    "#Combining Cluster Labels for Records 0 - 9999 with predictions for records 10000 to 20000\n",
    "#cluster.append(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeansT.inverse_transform(data[10000:10100]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Topic Extraction Using Gensim's Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option: This could be used if I have time to add a prediction feature to this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "text = rev1.map(lambda x: x.split())\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "model = Word2Vec(text, size=100, window=5, min_count=5)#, workers=3)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time()\n",
    "print model.most_similar(positive=['customer', 'service'])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print model.most_similar(positive=['service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print model\n",
    "print model['service']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
